{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a7d32-722a-41b0-82f4-60d8a8756c51",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc173d-bd11-4c0c-9bca-c878f4f35e1a",
   "metadata": {},
   "source": [
    "### Initial tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143026f-49ec-41c5-be9c-a4d6201535a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress warnings\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# also suppress warnings of parallel processes such as grid search cv\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e930a07-b425-40ef-9986-bdd1fe95023f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad54e9-0c99-4d25-8de7-7bb6d311388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-ins\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from termcolor import colored\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "# training\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc55ad-78ac-4a19-9820-ab3004ce7dd3",
   "metadata": {},
   "source": [
    "### Utils / Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163a10c-d78d-406c-8acc-4c6585222a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def cprint(text, color):\n",
    "    print(colored(text, color, attrs=['bold']))\n",
    "    \n",
    "def print_red(text):\n",
    "    cprint(text, 'red')\n",
    "\n",
    "def print_blue(text):\n",
    "    cprint(text, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4408a1-f1cd-43d3-8c83-f81fb45b42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDuration(object):\n",
    "    class printer(str):\n",
    "        def __repr__(self):\n",
    "            return self\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_tick = self.start_time\n",
    "        self.tick_count = 0\n",
    "        self.tick_times = 0\n",
    "        \n",
    "        self.completed = False\n",
    "        self.progress = 0\n",
    "        self.ert = 0\n",
    "        self.att = 0\n",
    "        self.out = None\n",
    "        \n",
    "        return self.tick\n",
    "  \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "        \n",
    "        self.completed = True\n",
    "        self.render()\n",
    "        \n",
    "    def tdformat(self, seconds):\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "    \n",
    "    def render(self):\n",
    "        output = ''\n",
    "        \n",
    "        if self.completed:\n",
    "            complete_time = (datetime.now() - self.start_time).total_seconds()\n",
    "            complete_time = self.tdformat(complete_time)\n",
    "            output = f'100% completed, total run time = {complete_time}'\n",
    "        else:\n",
    "            percent = round(self.progress * 100)\n",
    "            att = self.tdformat(self.att)\n",
    "            ert = self.tdformat(self.ert)\n",
    "            output = f'{percent}% completed, remaining time = {ert}, avg ticktime = {att}'\n",
    "        \n",
    "        output = self.printer(output)\n",
    "        \n",
    "        if self.out is None:\n",
    "            self.out = display(output, display_id=True)\n",
    "        else:\n",
    "            self.out.update(output)\n",
    "    \n",
    "    def tick(self, progress):\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # calculate\n",
    "        work_time = (now - self.start_time).total_seconds()\n",
    "        tick_time = (now - self.last_tick).total_seconds()\n",
    "        self.tick_count += 1\n",
    "        self.tick_times += tick_time\n",
    "        avg_tick_time = self.tick_times // self.tick_count\n",
    "        \n",
    "        if progress > 0:\n",
    "            total_ticks = self.tick_count // progress\n",
    "            remained_ticks = total_ticks - self.tick_count\n",
    "            est_remain_time = avg_tick_time * remained_ticks\n",
    "        else:\n",
    "            est_remain_time = 0\n",
    "            \n",
    "        # set\n",
    "        self.progress = progress\n",
    "        self.att = avg_tick_time\n",
    "        self.ert = est_remain_time\n",
    "        \n",
    "        # render\n",
    "        self.render()             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18943581-e40f-435d-bcef-7cd4a8f6212e",
   "metadata": {},
   "source": [
    "### Detect Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f0e2d-5aca-4294-baf2-baf8e9269aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28700259-a191-43cb-85a1-2ce3bf588886",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db2d48-2c0f-431f-a2f3-7e4e994d1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    path_root = '/kaggle/working'\n",
    "    path_dataset = '/kaggle/input/aihw2'\n",
    "    path_csv = path.join(path_dataset, 'csv')\n",
    "    path_csv_output = path_root\n",
    "    path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfcc08-80a2-416a-b2a2-d11b2e0a001a",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c89843-6e93-41cb-a826-585e16471e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_autosave_models = False\n",
    "cfg_force_train = False\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    cfg_autosave_models = True\n",
    "    cfg_force_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238567f7-de6c-4214-8605-3719e596503a",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f5a0f-49a3-4a01-8de8-9eae79a2fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_seed = 7908\n",
    "hp_cv_splits = 10\n",
    "hp_test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae22b3-b006-4c6d-9507-9b861ecf9914",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831b08e-d8ec-4368-8311-39276d74d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_employement_duration(entry):\n",
    "    entry = str(entry).lower()\n",
    "    split = entry.split(' ')\n",
    "    num = split[0]\n",
    "    output = entry\n",
    "    \n",
    "    if \"-\" in num:\n",
    "        num = num.split(\"-\")[1]\n",
    "    \n",
    "    if \"weeks\" in entry:\n",
    "        output = float(num) / 52\n",
    "    elif (\"month\" in entry) or (\"ay\" in entry):\n",
    "        output = float(num) / 12\n",
    "    elif (\"years\" in entry) or (\"sene\" in entry) or (\"yÄ±l\" in entry):\n",
    "        output = float(num)\n",
    "    else:\n",
    "        try:\n",
    "            output = float(num)\n",
    "        except:\n",
    "            output = 0\n",
    "        \n",
    "    output = round(output, 3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbcef0-c9ce-4315-9ca3-66e759f41875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read encodings\n",
    "encodings = load_json(path.join(path_dataset, 'encodings.json'))\n",
    "\n",
    "# read csvs\n",
    "csv_en = pd.read_csv(path.join(path_csv, 'english.csv'), dtype=str, encoding='utf-8')\n",
    "csv_tr = pd.read_csv(path.join(path_csv, 'turkish.csv'), dtype=str, encoding='utf-8')\n",
    "\n",
    "# drop columns\n",
    "csv_en.drop('Timestamp', axis=1, inplace=True)\n",
    "csv_tr.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "# rename columns\n",
    "csv_en.rename(columns=encodings['columns']['en'], inplace=True)\n",
    "csv_tr.rename(columns=encodings['columns']['tr'], inplace=True)\n",
    "\n",
    "# encode columns\n",
    "csv_en.replace(encodings['values']['en'], inplace=True)\n",
    "csv_tr.replace(encodings['values']['tr'], inplace=True)\n",
    "\n",
    "# concat csvs\n",
    "df = pd.concat([csv_en, csv_tr], axis=0).reset_index(drop=True)\n",
    "\n",
    "# fix NaNs\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# convert types\n",
    "df['age'] = df['age'].apply(lambda x: int(x))\n",
    "df['weight'] = df['weight'].apply(lambda x: int(float(x.replace(',', '.'))))\n",
    "df['height'] = df['height'].apply(lambda x: int(x.translate({ord(x): '' for x in [',', '.', ' ']})))\n",
    "df['employment_duration'] = df['employment_duration'].apply(map_employement_duration)\n",
    "\n",
    "# save csv\n",
    "df.to_csv(path.join(path_csv_output, 'data.csv'), index=None, header=True, encoding='utf-8-sig')\n",
    "df.info()\n",
    "\n",
    "# separate data and labels\n",
    "df_data = df.drop('weight', axis=1)\n",
    "df_labels = df['weight']\n",
    "\n",
    "# convert to numpy\n",
    "data = df_data.to_numpy()\n",
    "labels = df_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109dcdd1-6261-46f8-9db4-511e369f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b22c2-ea3f-4d69-a6c3-a12e44a71367",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ade675-ea00-4363-a825-a12624955463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, scale=False, scale_columns=None, pca=False, pca_n=None):\n",
    "        self.scale = scale\n",
    "        self.pca = pca\n",
    "        \n",
    "        if self.scale or self.pca:\n",
    "            self.scale_columns = scale_columns\n",
    "            self.scaler = preprocessing.StandardScaler()\n",
    "        \n",
    "        if self.pca:\n",
    "            self.pca_n = pca_n\n",
    "            self.PCA = PCA(n_components=pca_n, svd_solver='full', copy=True)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if self.pca:\n",
    "            data = self.scaler.fit_transform(data)\n",
    "            self.PCA.fit(data)\n",
    "        elif self.scale:\n",
    "            cols = self.scale_columns\n",
    "            self.scaler.fit(data[:, cols])\n",
    "        \n",
    "    def transform(self, data):\n",
    "        if self.pca:\n",
    "            data = self.scaler.transform(data)\n",
    "            data = self.PCA.transform(data)\n",
    "        elif self.scale:\n",
    "            cols = self.scale_columns\n",
    "            data[:, cols] = self.scaler.transform(data[:, cols])\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ac55c-e2d6-45c2-aaa8-fa680b65e80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, estimator, data, labels, n_splits, test_size, seed,\n",
    "                 prep_params={}, hp_grid=None):\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.hp_grid = hp_grid\n",
    "        \n",
    "        self.stats = []\n",
    "        self.best_stats = None\n",
    "        self.best_estimator = None\n",
    "    \n",
    "    def split(self):\n",
    "        split = ShuffleSplit(n_splits=self.n_splits, test_size=self.test_size, random_state=self.seed)\n",
    "        \n",
    "        for train_index, test_index in split.split(self.data):\n",
    "            train_data = (self.data[train_index], self.labels[train_index])\n",
    "            test_data = (self.data[test_index], self.labels[test_index])\n",
    "\n",
    "            yield(train_data, test_data)\n",
    "    \n",
    "    def train(self, tick=None):\n",
    "        for split_index, (train_data, test_data) in enumerate(self.split()):\n",
    "            if tick is not None:\n",
    "                tick(split_index/self.n_splits)\n",
    "            \n",
    "            X_train, Y_train = train_data\n",
    "            X_test, Y_test = test_data\n",
    "            \n",
    "            # create and use preprocessor\n",
    "            preprocessor = Preprocessor(**self.prep_params)\n",
    "            preprocessor.fit(X_train)\n",
    "            X_train = preprocessor.transform(X_train)\n",
    "            X_test = preprocessor.transform(X_test)\n",
    "            \n",
    "            estimator = self.estimator()\n",
    "            \n",
    "            # default values\n",
    "            best_params = None\n",
    "            best_estimator = estimator\n",
    "            \n",
    "            # fit estimator\n",
    "            if self.hp_grid is not None:\n",
    "                cv = GridSearchCV(estimator, self.hp_grid, cv=self.n_splits, n_jobs=-1)\n",
    "                cv.fit(X_train, Y_train)\n",
    "                \n",
    "                best_params = cv.best_params_\n",
    "                best_estimator = cv.best_estimator_\n",
    "            else:\n",
    "                best_estimator.fit(X_train, Y_train)\n",
    "            \n",
    "            Y_pred = best_estimator.predict(X_test)\n",
    "            rsme = round(np.sqrt(mean_squared_error(Y_test, Y_pred)), 2)\n",
    "            \n",
    "            result = dict(y_true=Y_test, y_pred=Y_pred, best_params=best_params, rsme=rsme,\n",
    "                          seed=self.seed, best_estimator=best_estimator, preprocessor=preprocessor)\n",
    "            \n",
    "            self.stats.append(result)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = data.copy()\n",
    "        self.best_preprocessor.transform(data)\n",
    "        return self.best_estimator.predict(data)\n",
    "    \n",
    "    def collect_best_stats(self):\n",
    "        best_rsme = math.inf\n",
    "        total_rsme = 0\n",
    "        best_stats = None\n",
    "        \n",
    "        for stats in self.stats:\n",
    "            rsme = stats['rsme']\n",
    "\n",
    "            total_rsme += rsme\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_stats = stats\n",
    "        \n",
    "        self.best_stats = best_stats\n",
    "        self.best_estimator = best_stats['best_estimator']\n",
    "        self.best_preprocessor = best_stats['preprocessor'] \n",
    "        self.mean_rsme = total_rsme / len(self.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8407d-4eb1-4509-9888-86ba12e5beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:   \n",
    "    def __init__(self, name, data, labels, n_splits, test_size, seed, prep_params={}):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.estimators = {}\n",
    "    \n",
    "    def set_estimators(self, estimators):\n",
    "        self.estimators = estimators\n",
    "    \n",
    "    def get_model_path(self, name):\n",
    "        return path.join(path_models, f'{self.name}_{name}.pickle')\n",
    "    \n",
    "    def save_model(self, name, model):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path,'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "        \n",
    "    def train_estimators(self, **kwargs):\n",
    "        estimators = kwargs.pop('estimators', self.estimators.keys())\n",
    "        for name in estimators:\n",
    "            print_red(f'Estimator: {name}\\n')\n",
    "            model = self.train_estimator(name, **kwargs)\n",
    "            yield (name, model)\n",
    "            \n",
    "    def train_estimator(self, name, reset=False, seed=None, save=True):      \n",
    "        if seed is None:\n",
    "            seed = self.seed\n",
    "        \n",
    "        if not reset:\n",
    "            try:\n",
    "                model = self.load_model(name)\n",
    "                setattr(self, name, model)\n",
    "                \n",
    "                print(f'Model {name} is loaded from disk successfully.')\n",
    "                return model\n",
    "            \n",
    "            except:\n",
    "                model = None\n",
    "        \n",
    "        name, estimator, hp_grid = self.estimators[name]\n",
    "        model = Model(estimator, self.data, self.labels, self.n_splits,\n",
    "                    self.test_size, seed, self.prep_params, hp_grid)\n",
    "        \n",
    "        with PrintDuration() as tick:\n",
    "            model.train(tick)\n",
    "\n",
    "        model.collect_best_stats()\n",
    "        setattr(self, name, model)\n",
    "        \n",
    "        if save:\n",
    "            self.save_model(name, model)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def search_best_seed(self, name, seed_range=100):\n",
    "        best_rsme = math.inf\n",
    "        best_seed = 0\n",
    "\n",
    "        for seed in range(seed_range):\n",
    "            estimator = self.train_estimator(name, seed, save=False)\n",
    "            rsme = estimator.best_stats[\"rsme\"]\n",
    "\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_seed = seed\n",
    "                print(f'{seed} -> {rsme} - {estimator.mean_rsme}')\n",
    "        \n",
    "        print(f'Best seed found as {best_seed}')\n",
    "        return best_seed\n",
    "    \n",
    "    def get_results_dataframe(self, name, shuffle=False, ascending=False):\n",
    "        model = getattr(self, name)\n",
    "\n",
    "        true = model.best_stats['y_true'].reshape(-1)\n",
    "        pred = model.best_stats['y_pred'].reshape(-1)\n",
    "        \n",
    "        df = pd.DataFrame(data={\n",
    "            'true': true,\n",
    "            'prediction': pred,\n",
    "            'diff': np.absolute(true - pred)\n",
    "        })\n",
    "    \n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1)\n",
    "        else:\n",
    "            df = df.sort_values('diff', ascending=ascending)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_stats(self, name):\n",
    "        model = getattr(self, name)\n",
    "        print('best_rsme', model.best_stats['rsme'])\n",
    "        print('mean_rsme', model.mean_rsme)\n",
    "        print('best_params', model.best_stats['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef593e3-f4d3-47ee-bc9c-66beeee91c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTrainer:\n",
    "    def __init__(self):\n",
    "        self.estimators = {}\n",
    "        self.trainer_names = []\n",
    "        \n",
    "    def add_estimator(self, name, estimator, hp_grid=None):\n",
    "        self.estimators[name] = (name, estimator, hp_grid)\n",
    "        \n",
    "    def add_trainer(self, **kwargs):\n",
    "        name = kwargs['name']\n",
    "        trainer = Trainer(**kwargs)\n",
    "        trainer.set_estimators(self.estimators)\n",
    "        \n",
    "        self.trainer_names.append(name)\n",
    "        setattr(self, name, trainer)\n",
    "        \n",
    "    def run_trainer(self, name, **kwargs):\n",
    "        trainer = getattr(self, name)\n",
    "        for (model_name, model) in trainer.train_estimators(**kwargs):\n",
    "            yield (name, trainer, model_name, model)\n",
    "            \n",
    "    def run_all_trainers(self, **kwargs):\n",
    "        trainers = kwargs.pop('trainers', self.trainer_names)\n",
    "        count = len(trainers)\n",
    "        \n",
    "        for index, name in enumerate(trainers):\n",
    "            print_blue(f'Trainer {index+1}/{count}: {name}\\n')\n",
    "            for (trainer_name, trainer, model_name, model) in self.run_trainer(name, **kwargs):\n",
    "                yield (trainer_name, trainer, model_name, model)\n",
    "    \n",
    "set_trainer = SetTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fda48-73bf-4fb7-bc92-85b6093a94e8",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bc666-9b3f-49dd-b1ef-e1c6f95e6eee",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12548-8179-4a7e-a6a8-8661c1d815f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importances(data, labels, n_splits, test_size, seed, prep_params={}):\n",
    "    model = Model(RandomForestRegressor, data, labels, n_splits, test_size, seed, prep_params)\n",
    "    model.train()\n",
    "    model.collect_best_stats()\n",
    "    \n",
    "    importances = model.best_estimator.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [df.columns.to_list()[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "    \n",
    "calculate_feature_importances(data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                              test_size=hp_test_size, seed=hp_seed,\n",
    "                              prep_params={'scale':True, 'scale_columns':[0, 1, 10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b38a7-8bf9-4dca-ac8e-75cea7701462",
   "metadata": {},
   "source": [
    "### Explained Variance Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04e932-a155-4551-a9f0-3d418aca9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_explained_variance_ratio(data, p=0.95):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=None, svd_solver='full', copy=True)\n",
    "    reduced = pca.fit_transform(X)\n",
    "    \n",
    "    # extract the smallest number of components which\n",
    "    # explain at least p% (e.g. 80%) of the variance\n",
    "    n_components = 1 + np.argmax(np.cumsum(pca.explained_variance_ratio_) >= p)\n",
    "    print(f'For p={int(p*100)}% n_components should be {n_components}\\n')\n",
    "\n",
    "    # extract the values of the selected components\n",
    "    #Z = pca.transform(X)[:, :n_components]\n",
    "    \n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "calculate_explained_variance_ratio(data, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8fe364-eca6-45c4-82f8-c8880618391f",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12aed6-0370-474a-88fd-645562b891d7",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd5c61-bc9a-4938-a79d-5e2371fd39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('linear', LinearRegression, {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [False, True], \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600a1ae-4d19-40dd-bbe9-d21476d9cf2c",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "\n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35298df2-7da1-46c9-9642-091bcfcf1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('svr', SVR, {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C': [1, 10, 100],\n",
    "    'epsilon': [0.05, 0.1, 0.2]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fb5f4-03d6-4de9-9a0a-8f596e663faf",
   "metadata": {},
   "source": [
    "## Bayesian Ridge\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059b347-44df-4677-adfc-14978ea26672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('br', BayesianRidge, {\n",
    "    'n_iter': [300, 500, 700]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2158a3e-6130-4b84-903b-95d2f1c8345b",
   "metadata": {},
   "source": [
    "## kNN\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf034b2-3e6f-412b-9f8f-be4943e3966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('knn', KNeighborsRegressor, {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93224b5d-77bc-405a-875d-9d07426f9abe",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73158db5-535e-41b3-8712-4249c0a733ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('dt', DecisionTreeRegressor, {\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': [1, 0.8, 0.5],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db28f3-66e7-4b0f-a5fa-b689f552dcee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bagging\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e585b-a0e6-4956-ac5e-1b961e2b30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('bag', BaggingRegressor, {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_samples': [1, 0.8, 0.5],\n",
    "    'max_features': [1, 0.8, 0.5],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322665e-6d62-4013-932b-acc819c432e5",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a44030-1a39-4d68-8ec8-d000dbc270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('rf', RandomForestRegressor, {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': [1, 0.8, 0.5],\n",
    "    'max_samples': [1, 0.8, 0.5],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6c854-11b5-4afd-9826-3fb33908020b",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "[doc](https://xgboost.readthedocs.io/en/stable/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10625ed-edf5-44bf-806f-696ac549fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('xgb', XGBRegressor, {\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440bbe2-ee96-4eaa-9d72-3400462a212b",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7cbb0-e0be-473f-8712-a0b3a5f5e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('ada', AdaBoostClassifier, {\n",
    "    'learning_rate': [0.3, 0.5, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a6b59-f257-42e3-9cf5-f86bc6e0ff15",
   "metadata": {},
   "source": [
    "## LGBM\n",
    "\n",
    "[doc](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63122792-6c54-432e-8d37-c324e13c54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('lgbm', LGBMRegressor, {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "    'colsample_bytree': [0.5, 0.75, 1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e30800-586e-466f-bb0d-64c9dba74c39",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c922602-d0e3-40d3-a5dd-93e09ae94954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('mlp', MLPRegressor, {\n",
    "    'hidden_layer_sizes': [(100,), (128,128), (256,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'batch_size': ['auto', 16, 32],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.003, 0.01],\n",
    "    'early_stopping': [True],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53211f-a92a-4df3-b2eb-4fbf77146f12",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8708b0-bd3b-40c9-95d8-02e0f6338b86",
   "metadata": {},
   "source": [
    "## Trainer Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db38e9-f41f-407b-b874-ecfd290ecaa1",
   "metadata": {},
   "source": [
    "### Normalized Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb5b16-24fe-4ad0-adec-305ad9e43d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': True, 'scale_columns': [0, 1, 10], 'pca': False}\n",
    "\n",
    "set_trainer.add_trainer(name='normalized', data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e78aeb-346a-4a07-8b0f-21b5289910f1",
   "metadata": {},
   "source": [
    "### Feature Selected Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d36310-83b3-40e2-82e1-0039e927577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': True, 'scale_columns': [0, 1, 7], 'pca': False}\n",
    "fselected_data = np.delete(data, [6, 7, 8], 1) # drop married, children and student\n",
    "\n",
    "set_trainer.add_trainer(name='fselected', data=fselected_data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ac9fe-e19e-4b57-94b6-884317069f58",
   "metadata": {},
   "source": [
    "### PCA Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f87d1a-eb4b-4ae6-9618-5288b1a4d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': True, 'scale_columns': [0, 1, 10], 'pca': True, 'pca_n': 0.99}\n",
    "\n",
    "set_trainer.add_trainer(name='pca', data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036f8f3-02de-484b-a58c-1c7a14c14af8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1740e6-ce7b-457e-a4fd-06d765c5c75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    # set trainer parameters\n",
    "    #'trainers': [],\n",
    "    \n",
    "    # trainer parameters\n",
    "    #'estimators': [],\n",
    "    #'reset': False,\n",
    "    #'seed': None,\n",
    "    #'save': False,\n",
    "}\n",
    "\n",
    "for (trainer_name, trainer, model_name, model) in set_trainer.run_all_trainers(**options):\n",
    "    # Show stats.\n",
    "    print()\n",
    "    trainer.print_stats(model_name)\n",
    "    print()\n",
    "    \n",
    "    # Show predicts.\n",
    "    trainer.get_results_dataframe(model_name, ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9fd08-f690-4abb-8c2c-9d0635c3a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list(set_trainer.fselected.estimators.keys())\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cac625-0a69-4ac4-ac82-d50a36810436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_list = list(set_trainer.fselected.estimators.keys())\n",
    "model_list\n",
    "fselected = set_trainer.fselected\n",
    "rsme = []\n",
    "for model in model_list:\n",
    "    model = getattr(fselected, model)\n",
    "    rsme.append([d['rsme'] for d in model.stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bd4a8-753a-4d52-834e-dfd5e92bf75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cab7c2-3b5e-4485-9c4d-fe68bce1f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind \n",
    "ttest_result = []\n",
    "for i in range(len(rsme)):\n",
    "    for j in range(i+1,len(rsme[0])):\n",
    "        ttest = ttest_ind(rsme[i], rsme[j])\n",
    "        p_value = ttest[1]\n",
    "        if(p_value<0.05):\n",
    "            result = 'significantly different'\n",
    "        else:\n",
    "            result = 'not significantly different'\n",
    "        ttest_result.append({'first feature':model_list[i], 'second feature':model_list[j],\n",
    "                             't_value': ttest[0], 'p_value':ttest[1], 'result': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c9cf2-ba32-451b-8725-9f3ac75dcc57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttest_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e7483-1a70-4c31-a420-42747ee3c102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in ttest_result:\n",
    "    if i['result'] == 'significantly different':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39071e68-c669-4ba5-9b61-5455f02174ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_feature = np.array([d['first feature'] for d in ttest_result if d[\"result\"] == 'significantly different']).reshape(-1,1)\n",
    "second_feture = np.array([d['second feature'] for d in ttest_result if d[\"result\"] == 'significantly different']).reshape(-1,1)\n",
    "results = np.concatenate([first_feature,second_feture], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d3b1a-7d70-4f92-8189-c9b3b97e4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e294455-ff6d-4496-ac44-ead7d237acdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
