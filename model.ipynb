{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a7d32-722a-41b0-82f4-60d8a8756c51",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc173d-bd11-4c0c-9bca-c878f4f35e1a",
   "metadata": {},
   "source": [
    "### Initial tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143026f-49ec-41c5-be9c-a4d6201535a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e930a07-b425-40ef-9986-bdd1fe95023f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad54e9-0c99-4d25-8de7-7bb6d311388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-ins\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import traceback\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# common\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from termcolor import colored\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "\n",
    "# training\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc55ad-78ac-4a19-9820-ab3004ce7dd3",
   "metadata": {},
   "source": [
    "### Utils / Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163a10c-d78d-406c-8acc-4c6585222a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def cprint(text, color):\n",
    "    print(colored(text, color, attrs=['bold']))\n",
    "    \n",
    "def print_red(text):\n",
    "    cprint(text, 'red')\n",
    "\n",
    "def print_blue(text):\n",
    "    cprint(text, 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4408a1-f1cd-43d3-8c83-f81fb45b42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintDuration(object):\n",
    "    def __enter__(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_tick = self.start_time\n",
    "        self.tick_count = 0\n",
    "        self.tick_times = 0\n",
    "        self.out = None\n",
    "        \n",
    "        return self.tick\n",
    "  \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is not None:\n",
    "            traceback.print_exception(exc_type, exc_value, tb)\n",
    "        \n",
    "        self.out.update(self.printer(''))\n",
    "        \n",
    "    class printer(str):\n",
    "        def __repr__(self):\n",
    "            return self\n",
    "        \n",
    "    def tdformat(self, seconds):\n",
    "        hours, remainder = divmod(seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n",
    "    \n",
    "    def tick(self, progress):\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # calculate\n",
    "        work_time = (now - self.start_time).total_seconds()\n",
    "        tick_time = (now - self.last_tick).total_seconds()\n",
    "        self.tick_count += 1\n",
    "        self.tick_times += tick_time\n",
    "\n",
    "        avg_tick_time = self.tick_times // self.tick_count\n",
    "        \n",
    "        if progress > 0:\n",
    "            total_ticks = self.tick_count // progress\n",
    "            remained_ticks = total_ticks - self.tick_count\n",
    "            est_remain_time = avg_tick_time * remained_ticks\n",
    "        else:\n",
    "            est_remain_time = 0\n",
    "            \n",
    "        # format\n",
    "        percent = round(progress*100)\n",
    "        att = self.tdformat(avg_tick_time)\n",
    "        ert = self.tdformat(est_remain_time)\n",
    "        \n",
    "        output = f'{percent}% completed, remaining time = {ert}, average tick time = {att}'\n",
    "        output = self.printer(output)\n",
    "        \n",
    "        if self.out is None:\n",
    "            self.out = display(output, display_id=True)\n",
    "        else:\n",
    "            self.out.update(output)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18943581-e40f-435d-bcef-7cd4a8f6212e",
   "metadata": {},
   "source": [
    "### Detect Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f0e2d-5aca-4294-baf2-baf8e9269aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28700259-a191-43cb-85a1-2ce3bf588886",
   "metadata": {},
   "source": [
    "### Path Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db2d48-2c0f-431f-a2f3-7e4e994d1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '.'\n",
    "path_dataset = path.join(path_root, 'dataset')\n",
    "path_csv = path.join(path_dataset, 'csv')\n",
    "path_csv_output =  path_csv\n",
    "path_models = path.join(path_root, 'models')\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    path_root = '/kaggle/working'\n",
    "    path_dataset = '/kaggle/input/aihw2'\n",
    "    path_csv = path.join(path_dataset, 'csv')\n",
    "    path_csv_output = path_root\n",
    "    path_models = path.join(path_root, 'models')\n",
    "    \n",
    "# Create directories.\n",
    "Path(path_models).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dfcc08-80a2-416a-b2a2-d11b2e0a001a",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c89843-6e93-41cb-a826-585e16471e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_autosave_models = False\n",
    "cfg_force_train = False\n",
    "\n",
    "if ENV_KAGGLE:\n",
    "    cfg_autosave_models = True\n",
    "    cfg_force_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238567f7-de6c-4214-8605-3719e596503a",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f5a0f-49a3-4a01-8de8-9eae79a2fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_seed = 7908\n",
    "hp_cv_splits = 10\n",
    "hp_test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae22b3-b006-4c6d-9507-9b861ecf9914",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831b08e-d8ec-4368-8311-39276d74d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_employement_duration(entry):\n",
    "    entry = str(entry).lower()\n",
    "    split = entry.split(' ')\n",
    "    num = split[0]\n",
    "    output = entry\n",
    "    \n",
    "    if \"-\" in num:\n",
    "        num = num.split(\"-\")[1]\n",
    "    \n",
    "    if \"weeks\" in entry:\n",
    "        output = float(num) / 52\n",
    "    elif (\"month\" in entry) or (\"ay\" in entry):\n",
    "        output = float(num) / 12\n",
    "    elif (\"years\" in entry) or (\"sene\" in entry) or (\"yÄ±l\" in entry):\n",
    "        output = float(num)\n",
    "    else:\n",
    "        try:\n",
    "            output = float(num)\n",
    "        except:\n",
    "            output = 0\n",
    "        \n",
    "    output = round(output, 3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbcef0-c9ce-4315-9ca3-66e759f41875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read encodings\n",
    "encodings = load_json(path.join(path_dataset, 'encodings.json'))\n",
    "\n",
    "# read csvs\n",
    "csv_en = pd.read_csv(path.join(path_csv, 'english.csv'), dtype=str, encoding='utf-8')\n",
    "csv_tr = pd.read_csv(path.join(path_csv, 'turkish.csv'), dtype=str, encoding='utf-8')\n",
    "\n",
    "# drop columns\n",
    "csv_en.drop('Timestamp', axis=1, inplace=True)\n",
    "csv_tr.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "# rename columns\n",
    "csv_en.rename(columns=encodings['columns']['en'], inplace=True)\n",
    "csv_tr.rename(columns=encodings['columns']['tr'], inplace=True)\n",
    "\n",
    "# encode columns\n",
    "csv_en.replace(encodings['values']['en'], inplace=True)\n",
    "csv_tr.replace(encodings['values']['tr'], inplace=True)\n",
    "\n",
    "# concat csvs\n",
    "df = pd.concat([csv_en, csv_tr], axis=0).reset_index(drop=True)\n",
    "\n",
    "# fix NaNs\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# convert types\n",
    "df['age'] = df['age'].apply(lambda x: int(x))\n",
    "df['weight'] = df['weight'].apply(lambda x: int(float(x.replace(',', '.'))))\n",
    "df['height'] = df['height'].apply(lambda x: int(x.translate({ord(x): '' for x in [',', '.', ' ']})))\n",
    "df['employment_duration'] = df['employment_duration'].apply(map_employement_duration)\n",
    "\n",
    "# save csv\n",
    "df.to_csv(path.join(path_csv_output, 'data.csv'), index=None, header=True, encoding='utf-8-sig')\n",
    "df.info()\n",
    "\n",
    "# separate data and labels\n",
    "df_data = df.drop('weight', axis=1)\n",
    "df_labels = df['weight']\n",
    "\n",
    "# convert to numpy\n",
    "data = df_data.to_numpy()\n",
    "labels = df_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109dcdd1-6261-46f8-9db4-511e369f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b22c2-ea3f-4d69-a6c3-a12e44a71367",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ade675-ea00-4363-a825-a12624955463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, scale=False, scale_columns=None):\n",
    "        self.scale = scale\n",
    "    \n",
    "        if self.scale:\n",
    "            self.scale_columns = scale_columns\n",
    "            self.scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if self.scale:\n",
    "            cols = self.scale_columns\n",
    "            self.scaler.fit(data[:, cols])\n",
    "        \n",
    "    def transform(self, data):\n",
    "        if self.scale:\n",
    "            cols = self.scale_columns\n",
    "            data[:, cols] = self.scaler.transform(data[:, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ac55c-e2d6-45c2-aaa8-fa680b65e80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, estimator, data, labels, n_splits, test_size, seed,\n",
    "                 prep_params={}, hp_grid=None):\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.hp_grid = hp_grid\n",
    "        \n",
    "        self.stats = []\n",
    "        self.best_stats = None\n",
    "        self.best_estimator = None\n",
    "    \n",
    "    def split(self):\n",
    "        split = ShuffleSplit(n_splits=self.n_splits, test_size=self.test_size, random_state=self.seed)\n",
    "        \n",
    "        for train_index, test_index in split.split(self.data):\n",
    "            train_data = (self.data[train_index], self.labels[train_index])\n",
    "            test_data = (self.data[test_index], self.labels[test_index])\n",
    "\n",
    "            yield(train_data, test_data)\n",
    "    \n",
    "    def train(self, tick=None):\n",
    "        for split_index, (train_data, test_data) in enumerate(self.split()):\n",
    "            if tick is not None:\n",
    "                tick(split_index/self.n_splits)\n",
    "            \n",
    "            X_train, Y_train = train_data\n",
    "            X_test, Y_test = test_data\n",
    "            \n",
    "            # create and use preprocessor\n",
    "            preprocessor = Preprocessor(**self.prep_params)\n",
    "            preprocessor.fit(X_train)\n",
    "            preprocessor.transform(X_train)\n",
    "            preprocessor.transform(X_test)\n",
    "            \n",
    "            estimator = self.estimator()\n",
    "            \n",
    "            # default values\n",
    "            best_params = None\n",
    "            best_estimator = estimator\n",
    "            \n",
    "            # fit estimator\n",
    "            if self.hp_grid is not None:\n",
    "                cv = GridSearchCV(estimator, self.hp_grid, cv=self.n_splits, n_jobs=-1)\n",
    "                cv.fit(X_train, Y_train)\n",
    "                \n",
    "                best_params = cv.best_params_\n",
    "                best_estimator = cv.best_estimator_\n",
    "            else:\n",
    "                best_estimator.fit(X_train, Y_train)\n",
    "            \n",
    "            Y_pred = best_estimator.predict(X_test)\n",
    "            rsme = round(np.sqrt(mean_squared_error(Y_test, Y_pred)), 2)\n",
    "            \n",
    "            result = dict(y_true=Y_test, y_pred=Y_pred, best_params=best_params, rsme=rsme,\n",
    "                          seed=self.seed, best_estimator=best_estimator, preprocessor=preprocessor)\n",
    "            \n",
    "            self.stats.append(result)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = data.copy()\n",
    "        self.best_preprocessor.transform(data)\n",
    "        return self.best_estimator.predict(data)\n",
    "    \n",
    "    def collect_best_stats(self):\n",
    "        best_rsme = math.inf\n",
    "        total_rsme = 0\n",
    "        best_stats = None\n",
    "        \n",
    "        for stats in self.stats:\n",
    "            rsme = stats['rsme']\n",
    "\n",
    "            total_rsme += rsme\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_stats = stats\n",
    "        \n",
    "        self.best_stats = best_stats\n",
    "        self.best_estimator = best_stats['best_estimator']\n",
    "        self.best_preprocessor = best_stats['preprocessor'] \n",
    "        self.mean_rsme = total_rsme / len(self.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8407d-4eb1-4509-9888-86ba12e5beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:   \n",
    "    def __init__(self, name, data, labels, n_splits, test_size, seed, prep_params={}):\n",
    "        self.name = name\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.seed = seed\n",
    "        self.prep_params = prep_params\n",
    "        self.estimators = {}\n",
    "    \n",
    "    def set_estimators(self, estimators):\n",
    "        self.estimators = estimators\n",
    "    \n",
    "    def get_model_path(self, name):\n",
    "        return path.join(path_models, f'{self.name}_{name}.pickle')\n",
    "    \n",
    "    def save_model(self, name, model):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path,'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        model_path = self.get_model_path(name)\n",
    "        with open(model_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "        \n",
    "    def train_all_estimators(self, **kwargs):\n",
    "        for name in self.estimators.keys():\n",
    "            print_red(f'Estimator: {name}\\n')\n",
    "            model = self.train_estimator(name, **kwargs)\n",
    "            yield (name, model)\n",
    "            \n",
    "    def train_estimator(self, name, reset=False, seed=None, save=True):\n",
    "        if seed is None:\n",
    "            seed = self.seed\n",
    "        \n",
    "        if not reset:\n",
    "            try:\n",
    "                model = self.load_model(name)\n",
    "                setattr(self, name, model)\n",
    "                \n",
    "                print(f'Model {name} is loaded from disk successfully.\\n')\n",
    "                return model\n",
    "            \n",
    "            except:\n",
    "                model = None\n",
    "        \n",
    "        name, estimator, hp_grid = self.estimators[name]\n",
    "        model = Model(estimator, self.data, self.labels, self.n_splits,\n",
    "                    self.test_size, seed, self.prep_params, hp_grid)\n",
    "        \n",
    "        with PrintDuration() as tick:\n",
    "            model.train(tick)\n",
    "\n",
    "        model.collect_best_stats()\n",
    "        \n",
    "        if save:\n",
    "            setattr(self, name, model)\n",
    "            self.save_model(name, model)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def search_best_seed(self, name, seed_range=100):\n",
    "        best_rsme = math.inf\n",
    "        best_seed = 0\n",
    "\n",
    "        for seed in range(seed_range):\n",
    "            estimator = self.train_estimator(name, seed, save=False)\n",
    "            rsme = estimator.best_stats[\"rsme\"]\n",
    "\n",
    "            if rsme < best_rsme:\n",
    "                best_rsme = rsme\n",
    "                best_seed = seed\n",
    "                print(f'{seed} -> {rsme} - {estimator.mean_rsme}')\n",
    "        \n",
    "        print(f'Best seed found as {best_seed}')\n",
    "        return best_seed\n",
    "    \n",
    "    def get_results_dataframe(self, name, shuffle=False, ascending=False):\n",
    "        model = getattr(self, name)\n",
    "\n",
    "        true = model.best_stats['y_true'].reshape(-1)\n",
    "        pred = model.best_stats['y_pred'].reshape(-1)\n",
    "        \n",
    "        df = pd.DataFrame(data={\n",
    "            'true': true,\n",
    "            'prediction': pred,\n",
    "            'diff': np.absolute(true - pred)\n",
    "        })\n",
    "    \n",
    "        if shuffle:\n",
    "            df = df.sample(frac=1)\n",
    "        else:\n",
    "            df = df.sort_values('diff', ascending=ascending)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def print_stats(self, name):\n",
    "        model = getattr(self, name)\n",
    "        print('best_rsme', model.best_stats['rsme'])\n",
    "        print('mean_rsme', model.mean_rsme)\n",
    "        print('best_params', model.best_stats['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef593e3-f4d3-47ee-bc9c-66beeee91c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTrainer:\n",
    "    def __init__(self):\n",
    "        self.estimators = {}\n",
    "        self.trainer_names = []\n",
    "        \n",
    "    def add_estimator(self, name, estimator, hp_grid=None):\n",
    "        self.estimators[name] = (name, estimator, hp_grid)\n",
    "        \n",
    "    def add_trainer(self, **kwargs):\n",
    "        name = kwargs['name']\n",
    "        trainer = Trainer(**kwargs)\n",
    "        trainer.set_estimators(self.estimators)\n",
    "        \n",
    "        self.trainer_names.append(name)\n",
    "        setattr(self, name, trainer)\n",
    "        \n",
    "    def run_trainer(self, name):\n",
    "        trainer = getattr(self, name)\n",
    "        for (model_name, model) in trainer.train_all_estimators():\n",
    "            yield (name, trainer, model_name, model)\n",
    "            \n",
    "    def run_all_trainers(self):\n",
    "        count = len(self.trainer_names)\n",
    "        for index, name in enumerate(self.trainer_names):\n",
    "            print_blue(f'Trainer {index+1}/{count}: {name}\\n')\n",
    "            for (trainer_name, trainer, model_name, model) in self.run_trainer(name):\n",
    "                yield (trainer_name, trainer, model_name, model)\n",
    "    \n",
    "set_trainer = SetTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fda48-73bf-4fb7-bc92-85b6093a94e8",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12548-8179-4a7e-a6a8-8661c1d815f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importances(data, labels, n_splits, test_size, seed, prep_params={}):\n",
    "    model = Model(RandomForestRegressor, data, labels, n_splits, test_size, seed, prep_params)\n",
    "    model.train()\n",
    "    model.collect_best_stats()\n",
    "    \n",
    "    importances = model.best_estimator.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [df.columns.to_list()[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "    \n",
    "calculate_feature_importances(data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                              test_size=hp_test_size, seed=hp_seed,\n",
    "                              prep_params={'scale':True, 'scale_columns':[0, 1, 10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8fe364-eca6-45c4-82f8-c8880618391f",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12aed6-0370-474a-88fd-645562b891d7",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd5c61-bc9a-4938-a79d-5e2371fd39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('linear', LinearRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600a1ae-4d19-40dd-bbe9-d21476d9cf2c",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "\n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35298df2-7da1-46c9-9642-091bcfcf1fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('svr', SVR, {\n",
    "    'kernel': ('linear', 'rbf', 'poly'),\n",
    "    'C': [1.5, 10],\n",
    "    'gamma': [1e-7, 1e-4],\n",
    "    'epsilon': [0.1, 0.2, 0.3, 0.5]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fb5f4-03d6-4de9-9a0a-8f596e663faf",
   "metadata": {},
   "source": [
    "## Bayesian Ridge\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059b347-44df-4677-adfc-14978ea26672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('br', BayesianRidge, {\n",
    "    'n_iter': [300, 500, 700, 1000]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2158a3e-6130-4b84-903b-95d2f1c8345b",
   "metadata": {},
   "source": [
    "## kNN\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf034b2-3e6f-412b-9f8f-be4943e3966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('knn', KNeighborsRegressor, {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93224b5d-77bc-405a-875d-9d07426f9abe",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73158db5-535e-41b3-8712-4249c0a733ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('dt', DecisionTreeRegressor, {\n",
    "    'criterion': ['squared_error', 'absolute_error'],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db28f3-66e7-4b0f-a5fa-b689f552dcee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bagging\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e585b-a0e6-4956-ac5e-1b961e2b30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('bag', BaggingRegressor, {\n",
    "    'max_features': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [10, 20, 50, 100],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322665e-6d62-4013-932b-acc819c432e5",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a44030-1a39-4d68-8ec8-d000dbc270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('rf', RandomForestRegressor, {\n",
    "    'max_features': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [100, 200, 500, 1000]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6c854-11b5-4afd-9826-3fb33908020b",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "[doc](https://xgboost.readthedocs.io/en/stable/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10625ed-edf5-44bf-806f-696ac549fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('xgb', XGBRegressor, {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440bbe2-ee96-4eaa-9d72-3400462a212b",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7cbb0-e0be-473f-8712-a0b3a5f5e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('ada', AdaBoostClassifier, {\n",
    "    'loss': ['linear', 'square', 'exponential'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a6b59-f257-42e3-9cf5-f86bc6e0ff15",
   "metadata": {},
   "source": [
    "## LGBM\n",
    "\n",
    "[doc](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63122792-6c54-432e-8d37-c324e13c54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('lgbm', LGBMRegressor, {\n",
    "    'colsample_bytree': [0.4, 0.5, 0.6, 0.9, 1],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e30800-586e-466f-bb0d-64c9dba74c39",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "[doc](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c922602-d0e3-40d3-a5dd-93e09ae94954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add estimator\n",
    "set_trainer.add_estimator('mlp', MLPRegressor, {\n",
    "    'early_stopping': [True],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'hidden_layer_sizes': [(8,8), (16,16), (64,64)],\n",
    "    'batch_size': ['auto', 8, 16, 32, 64],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.003, 0.01],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53211f-a92a-4df3-b2eb-4fbf77146f12",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8708b0-bd3b-40c9-95d8-02e0f6338b86",
   "metadata": {},
   "source": [
    "## Trainer Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e8847-bd55-4f68-be47-fefa3e22e252",
   "metadata": {},
   "source": [
    "### Default Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598a17-d14d-45b9-a4fe-55649f0a9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': False}\n",
    "\n",
    "set_trainer.add_trainer(name='default', data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db38e9-f41f-407b-b874-ecfd290ecaa1",
   "metadata": {},
   "source": [
    "### Normalized Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb5b16-24fe-4ad0-adec-305ad9e43d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': True, 'scale_columns': [0, 1, 10]}\n",
    "\n",
    "set_trainer.add_trainer(name='normalized', data=data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e78aeb-346a-4a07-8b0f-21b5289910f1",
   "metadata": {},
   "source": [
    "### Feature Selected Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d36310-83b3-40e2-82e1-0039e927577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_params = {'scale': True, 'scale_columns': [0, 1, 7]}\n",
    "fselected_data = np.delete(data, [6, 7, 8], 1) # drop married, children and student\n",
    "\n",
    "set_trainer.add_trainer(name='fselected', data=fselected_data, labels=labels, n_splits=hp_cv_splits,\n",
    "                        test_size=hp_test_size, seed=hp_seed, prep_params=prep_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036f8f3-02de-484b-a58c-1c7a14c14af8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1740e6-ce7b-457e-a4fd-06d765c5c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (trainer_name, trainer, model_name, model) in set_trainer.run_all_trainers():\n",
    "    # Show stats.\n",
    "    trainer.print_stats(model_name)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Show predicts.\n",
    "    trainer.get_results_dataframe(model_name, ascending=True).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
